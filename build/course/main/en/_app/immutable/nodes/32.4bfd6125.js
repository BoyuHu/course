import{s as al,o as il}from"../chunks/scheduler.37c15a92.js";import{S as ol,i as rl,g as i,s,r,A as ml,h as o,f as l,c as a,j as nl,u as m,x as p,k as sl,y as pl,a as n,v as M,d,t as y,w as h,m as Ml,n as dl}from"../chunks/index.2bf4358c.js";import{T as yl}from"../chunks/Tip.363c041f.js";import{C as c}from"../chunks/CodeBlock.4f5fc1ad.js";import{C as hl}from"../chunks/CourseFloatingBanner.15ba07e6.js";import{H as w}from"../chunks/Heading.8ada512a.js";function ul(Ue){let u;return{c(){u=Ml("This exercise was written by LLM fine-tuning expert [@mlabonne](https://huggingface.co/mlabonne).")},l(J){u=dl(J,"This exercise was written by LLM fine-tuning expert [@mlabonne](https://huggingface.co/mlabonne).")},m(J,T){n(J,u,T)},d(J){J&&l(u)}}}function cl(Ue){let u,J,T,je,g,$e,b,Ie,U,Ct="Now that youâ€™ve seen the theory, letâ€™s put it into practice! In this exercise, youâ€™ll fine-tune a model with GRPO.",Ge,f,Ce,j,Be,$,Bt="First, letâ€™s install the dependencies for this exercise.",Ze,I,ve,G,Zt="Now weâ€™ll import the necessary libraries.",We,C,xe,B,Re,Z,vt="Weights & Biases is a tool for logging and monitoring your experiments. Weâ€™ll use it to log our fine-tuning process.",Xe,v,Fe,W,Wt="You can do this exercise without logging in to Weights & Biases, but itâ€™s recommended to do so to track your experiments and interpret the results.",_e,x,ke,R,xt='Now, letâ€™s load the dataset. In this case, weâ€™ll use the <a href="https://huggingface.co/datasets/mlabonne/smoltldr" rel="nofollow"><code>mlabonne/smoltldr</code></a> dataset, which contains a list of short stories.',Qe,X,Ve,F,Ye,_,Rt="Now, letâ€™s load the model.",ze,k,Xt='For this exercise, weâ€™ll use the <a href="hhttps://huggingface.co/HuggingFaceTB/SmolLM2-135M"><code>SmolLM2-135M</code></a> model.',Ne,Q,Ft='This is a small 135M parameter model that runs on limited hardware. This makes the model ideal for learning, but itâ€™s not the most powerful model out there. If you have access to more powerful hardware, you can try to fine-tune a larger model like <a href="https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B" rel="nofollow"><code>SmolLM2-1.7B</code></a>.',Ee,V,He,Y,Ae,z,_t="Now, letâ€™s load the LoRA configuration. Weâ€™ll take advantage of LoRA to reduce the number of trainable parameters, and in turn the memory footprint we need to fine-tune the model.",Se,N,kt='If youâ€™re not familiar with LoRA, you can read more about it in <a href="https://huggingface.co/learn/course/en/chapter11/3" rel="nofollow">Chapter 11</a>.',qe,E,Le,H,Pe,A,De,S,Qt="As mentioned in the previous section, GRPO can use any reward function to improve the model. In this case, weâ€™ll use a simple reward function that encourages the model to generate text that is 50 tokens long.",Oe,q,Ke,L,et,P,Vt="Now, letâ€™s define the training arguments. Weâ€™ll use the <code>GRPOConfig</code> class to define the training arguments in a typical <code>transformers</code> style.",tt,D,Yt='If this is the first time youâ€™re defining training arguments, you can check the <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer#trainingarguments" rel="nofollow">TrainingArguments</a> class for more information, or <a href="https://huggingface.co/learn/course/en/chapter2/1" rel="nofollow">Chapter 2</a> for a detailed introduction.',lt,O,nt,K,zt="Now, we can initialize the trainer with model, dataset, and training arguments and start training.",st,ee,at,te,Nt="Training takes around 1 hour on a single A10G GPU which is available on Google Colab or via Hugging Face Spaces.",it,le,ot,ne,Et="If we set the <code>push_to_hub</code> argument to <code>True</code> and the <code>model_id</code> argument to a valid model name, the model will be pushed to the Hugging Face Hub whilst weâ€™re training. This is useful if you want to start vibe testing the model straight away!",rt,se,mt,ae,Ht="<code>GRPOTrainer</code> logs the reward from your reward function, the loss, and a range of other metrics.",pt,ie,At="We will focus on the reward from the reward function and the loss.",Mt,oe,St="As you can see, the reward from the reward function moves closer to 0 as the model learns. This is a good sign that the model is learning to generate text of the correct length.",dt,re,qt='<img src="https://huggingface.co/reasoning-course/images/resolve/main/grpo/13.png" alt="Reward from reward function"/>',yt,me,Lt="You might notice that the loss starts at zero and then increases during training, which may seem counterintuitive. This behavior is expected in GRPO and is directly related to the mathematical formulation of the algorithm. The loss in GRPO is proportional to the KL divergence (the cap relative to original policy) . As training progresses, the model learns to generate text that better matches the reward function, causing it to diverge more from its initial policy. This increasing divergence is reflected in the rising loss value, which actually indicates that the model is successfully adapting to optimize for the reward function.",ht,pe,Pt='<img src="https://huggingface.co/reasoning-course/images/resolve/main/grpo/14.png" alt="Loss"/>',ut,Me,ct,de,Dt="Letâ€™s share the model with the community!",wt,ye,Jt,he,ft,ue,Ot="ðŸŽ‰ Youâ€™ve successfully fine-tuned a model with GRPO! Now, letâ€™s generate some text with the model.",Tt,ce,Kt="First, weâ€™ll define a really long document!",gt,we,bt,Je,el="Now, we can generate text with the model.",Ut,fe,jt,Te,$t,ge,tl="In this chapter, weâ€™ve seen how to fine-tune a model with GRPO. Weâ€™ve also seen how to interpret the training results and generate text with the model.",It,be,Gt;return g=new hl({props:{chapter:2,classNames:"absolute z-10 right-0 top-0",notebooks:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/course/en/chapter12/grpo_finetune.ipynb"}]}}),b=new w({props:{title:"Practical Exercise: Fine-tune a model with GRPO",local:"practical-exercise-fine-tune-a-model-with-grpo",headingTag:"h1"}}),f=new yl({props:{$$slots:{default:[ul]},$$scope:{ctx:Ue}}}),j=new w({props:{title:"Install dependencies",local:"install-dependencies",headingTag:"h2"}}),I=new c({props:{code:"IXBpcCUyMGluc3RhbGwlMjAtcXFxJTIwZGF0YXNldHMlM0QlM0QzLjIuMCUyMHRyYW5zZm9ybWVycyUzRCUzRDQuNDcuMSUyMHRybCUzRCUzRDAuMTQuMCUyMHBlZnQlM0QlM0QwLjE0LjAlMjBhY2NlbGVyYXRlJTNEJTNEMS4yLjElMjBiaXRzYW5kYnl0ZXMlM0QlM0QwLjQ1LjIlMjB3YW5kYiUzRCUzRDAuMTkuNyUyMC0tcHJvZ3Jlc3MtYmFyJTIwb2ZmJTBBIXBpcCUyMGluc3RhbGwlMjAtcXFxJTIwZmxhc2gtYXR0biUyMC0tbm8tYnVpbGQtaXNvbGF0aW9uJTIwLS1wcm9ncmVzcy1iYXIlMjBvZmY=",highlighted:`!pip install -qqq datasets==3.2.0 transformers==4.47.1 trl==0.14.0 peft==0.14.0 accelerate==1.2.1 bitsandbytes==0.45.2 wandb==0.19.7 --progress-bar off
!pip install -qqq flash-attn --no-build-isolation --progress-bar off`,wrap:!1}}),C=new c({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwZGF0YXNldHMlMjBpbXBvcnQlMjBsb2FkX2RhdGFzZXQlMEFmcm9tJTIwcGVmdCUyMGltcG9ydCUyMExvcmFDb25maWclMkMlMjBnZXRfcGVmdF9tb2RlbCUwQWZyb20lMjB0cmFuc2Zvcm1lcnMlMjBpbXBvcnQlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTSUyQyUyMEF1dG9Ub2tlbml6ZXIlMEFmcm9tJTIwdHJsJTIwaW1wb3J0JTIwR1JQT0NvbmZpZyUyQyUyMEdSUE9UcmFpbmVy",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> LoraConfig, get_peft_model
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer
<span class="hljs-keyword">from</span> trl <span class="hljs-keyword">import</span> GRPOConfig, GRPOTrainer`,wrap:!1}}),B=new w({props:{title:"Import and log in to Weights & Biases",local:"import-and-log-in-to-weights--biases",headingTag:"h2"}}),v=new c({props:{code:"aW1wb3J0JTIwd2FuZGIlMEElMEF3YW5kYi5sb2dpbigp",highlighted:`<span class="hljs-keyword">import</span> wandb

wandb.login()`,wrap:!1}}),x=new w({props:{title:"Load the dataset",local:"load-the-dataset",headingTag:"h2"}}),X=new c({props:{code:"ZGF0YXNldCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJtbGFib25uZSUyRnNtb2x0bGRyJTIyKSUwQXByaW50KGRhdGFzZXQp",highlighted:`dataset = load_dataset(<span class="hljs-string">&quot;mlabonne/smoltldr&quot;</span>)
<span class="hljs-built_in">print</span>(dataset)`,wrap:!1}}),F=new w({props:{title:"Load model",local:"load-model",headingTag:"h2"}}),V=new c({props:{code:"bW9kZWxfaWQlMjAlM0QlMjAlMjJIdWdnaW5nRmFjZVRCJTJGU21vbExNLTEzNU0tSW5zdHJ1Y3QlMjIlMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjBtb2RlbF9pZCUyQyUwQSUyMCUyMCUyMCUyMHRvcmNoX2R0eXBlJTNEJTIyYXV0byUyMiUyQyUwQSUyMCUyMCUyMCUyMGRldmljZV9tYXAlM0QlMjJhdXRvJTIyJTJDJTBBJTIwJTIwJTIwJTIwYXR0bl9pbXBsZW1lbnRhdGlvbiUzRCUyMmZsYXNoX2F0dGVudGlvbl8yJTIyJTJDJTBBKSUwQXRva2VuaXplciUyMCUzRCUyMEF1dG9Ub2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKG1vZGVsX2lkKQ==",highlighted:`model_id = <span class="hljs-string">&quot;HuggingFaceTB/SmolLM-135M-Instruct&quot;</span>
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=<span class="hljs-string">&quot;auto&quot;</span>,
    device_map=<span class="hljs-string">&quot;auto&quot;</span>,
    attn_implementation=<span class="hljs-string">&quot;flash_attention_2&quot;</span>,
)
tokenizer = AutoTokenizer.from_pretrained(model_id)`,wrap:!1}}),Y=new w({props:{title:"Load LoRA",local:"load-lora",headingTag:"h2"}}),E=new c({props:{code:"JTIzJTIwTG9hZCUyMExvUkElMEFsb3JhX2NvbmZpZyUyMCUzRCUyMExvcmFDb25maWcoJTBBJTIwJTIwJTIwJTIwdGFza190eXBlJTNEJTIyQ0FVU0FMX0xNJTIyJTJDJTBBJTIwJTIwJTIwJTIwciUzRDE2JTJDJTBBJTIwJTIwJTIwJTIwbG9yYV9hbHBoYSUzRDMyJTJDJTBBJTIwJTIwJTIwJTIwdGFyZ2V0X21vZHVsZXMlM0QlMjJhbGwtbGluZWFyJTIyJTJDJTBBKSUwQW1vZGVsJTIwJTNEJTIwZ2V0X3BlZnRfbW9kZWwobW9kZWwlMkMlMjBsb3JhX2NvbmZpZyklMEFwcmludChtb2RlbC5wcmludF90cmFpbmFibGVfcGFyYW1ldGVycygpKQ==",highlighted:`<span class="hljs-comment"># Load LoRA</span>
lora_config = LoraConfig(
    task_type=<span class="hljs-string">&quot;CAUSAL_LM&quot;</span>,
    r=<span class="hljs-number">16</span>,
    lora_alpha=<span class="hljs-number">32</span>,
    target_modules=<span class="hljs-string">&quot;all-linear&quot;</span>,
)
model = get_peft_model(model, lora_config)
<span class="hljs-built_in">print</span>(model.print_trainable_parameters())`,wrap:!1}}),H=new c({props:{code:"VG90YWwlMjB0cmFpbmFibGUlMjBwYXJhbWV0ZXJzJTNBJTIwMTM1TQ==",highlighted:"Total trainable parameters: 135M",wrap:!1}}),A=new w({props:{title:"Define the reward function",local:"define-the-reward-function",headingTag:"h2"}}),q=new c({props:{code:"JTIzJTIwUmV3YXJkJTIwZnVuY3Rpb24lMEFpZGVhbF9sZW5ndGglMjAlM0QlMjA1MCUwQSUwQSUwQWRlZiUyMHJld2FyZF9sZW4oY29tcGxldGlvbnMlMkMlMjAqKmt3YXJncyklM0ElMEElMjAlMjAlMjAlMjByZXR1cm4lMjAlNUItYWJzKGlkZWFsX2xlbmd0aCUyMC0lMjBsZW4oY29tcGxldGlvbikpJTIwZm9yJTIwY29tcGxldGlvbiUyMGluJTIwY29tcGxldGlvbnMlNUQ=",highlighted:`<span class="hljs-comment"># Reward function</span>
ideal_length = <span class="hljs-number">50</span>


<span class="hljs-keyword">def</span> <span class="hljs-title function_">reward_len</span>(<span class="hljs-params">completions, **kwargs</span>):
    <span class="hljs-keyword">return</span> [-<span class="hljs-built_in">abs</span>(ideal_length - <span class="hljs-built_in">len</span>(completion)) <span class="hljs-keyword">for</span> completion <span class="hljs-keyword">in</span> completions]`,wrap:!1}}),L=new w({props:{title:"Define the training arguments",local:"define-the-training-arguments",headingTag:"h2"}}),O=new c({props:{code:"JTIzJTIwVHJhaW5pbmclMjBhcmd1bWVudHMlMEF0cmFpbmluZ19hcmdzJTIwJTNEJTIwR1JQT0NvbmZpZyglMEElMjAlMjAlMjAlMjBvdXRwdXRfZGlyJTNEJTIyR1JQTyUyMiUyQyUwQSUyMCUyMCUyMCUyMGxlYXJuaW5nX3JhdGUlM0QyZS01JTJDJTBBJTIwJTIwJTIwJTIwcGVyX2RldmljZV90cmFpbl9iYXRjaF9zaXplJTNEOCUyQyUwQSUyMCUyMCUyMCUyMGdyYWRpZW50X2FjY3VtdWxhdGlvbl9zdGVwcyUzRDIlMkMlMEElMjAlMjAlMjAlMjBtYXhfcHJvbXB0X2xlbmd0aCUzRDUxMiUyQyUwQSUyMCUyMCUyMCUyMG1heF9jb21wbGV0aW9uX2xlbmd0aCUzRDk2JTJDJTBBJTIwJTIwJTIwJTIwbnVtX2dlbmVyYXRpb25zJTNEOCUyQyUwQSUyMCUyMCUyMCUyMG9wdGltJTNEJTIyYWRhbXdfOGJpdCUyMiUyQyUwQSUyMCUyMCUyMCUyMG51bV90cmFpbl9lcG9jaHMlM0QxJTJDJTBBJTIwJTIwJTIwJTIwYmYxNiUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjByZXBvcnRfdG8lM0QlNUIlMjJ3YW5kYiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHJlbW92ZV91bnVzZWRfY29sdW1ucyUzREZhbHNlJTJDJTBBJTIwJTIwJTIwJTIwbG9nZ2luZ19zdGVwcyUzRDElMkMlMEEp",highlighted:`<span class="hljs-comment"># Training arguments</span>
training_args = GRPOConfig(
    output_dir=<span class="hljs-string">&quot;GRPO&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    per_device_train_batch_size=<span class="hljs-number">8</span>,
    gradient_accumulation_steps=<span class="hljs-number">2</span>,
    max_prompt_length=<span class="hljs-number">512</span>,
    max_completion_length=<span class="hljs-number">96</span>,
    num_generations=<span class="hljs-number">8</span>,
    optim=<span class="hljs-string">&quot;adamw_8bit&quot;</span>,
    num_train_epochs=<span class="hljs-number">1</span>,
    bf16=<span class="hljs-literal">True</span>,
    report_to=[<span class="hljs-string">&quot;wandb&quot;</span>],
    remove_unused_columns=<span class="hljs-literal">False</span>,
    logging_steps=<span class="hljs-number">1</span>,
)`,wrap:!1}}),ee=new c({props:{code:"JTIzJTIwVHJhaW5lciUwQXRyYWluZXIlMjAlM0QlMjBHUlBPVHJhaW5lciglMEElMjAlMjAlMjAlMjBtb2RlbCUzRG1vZGVsJTJDJTBBJTIwJTIwJTIwJTIwcmV3YXJkX2Z1bmNzJTNEJTVCcmV3YXJkX2xlbiU1RCUyQyUwQSUyMCUyMCUyMCUyMGFyZ3MlM0R0cmFpbmluZ19hcmdzJTJDJTBBJTIwJTIwJTIwJTIwdHJhaW5fZGF0YXNldCUzRGRhdGFzZXQlNUIlMjJ0cmFpbiUyMiU1RCUyQyUwQSklMEElMEElMjMlMjBUcmFpbiUyMG1vZGVsJTBBd2FuZGIuaW5pdChwcm9qZWN0JTNEJTIyR1JQTyUyMiklMEF0cmFpbmVyLnRyYWluKCk=",highlighted:`<span class="hljs-comment"># Trainer</span>
trainer = GRPOTrainer(
    model=model,
    reward_funcs=[reward_len],
    args=training_args,
    train_dataset=dataset[<span class="hljs-string">&quot;train&quot;</span>],
)

<span class="hljs-comment"># Train model</span>
wandb.init(project=<span class="hljs-string">&quot;GRPO&quot;</span>)
trainer.train()`,wrap:!1}}),le=new w({props:{title:"Push the model to the Hub during training",local:"push-the-model-to-the-hub-during-training",headingTag:"h2"}}),se=new w({props:{title:"Interpret training results",local:"interpret-training-results",headingTag:"h2"}}),Me=new w({props:{title:"Save and publish the model",local:"save-and-publish-the-model",headingTag:"h2"}}),ye=new c({props:{code:"bWVyZ2VkX21vZGVsJTIwJTNEJTIwdHJhaW5lci5tb2RlbC5tZXJnZV9hbmRfdW5sb2FkKCklMEFtZXJnZWRfbW9kZWwucHVzaF90b19odWIoJTBBJTIwJTIwJTIwJTIwJTIyU21vbEdSUE8tMTM1TSUyMiUyQyUyMHByaXZhdGUlM0RGYWxzZSUyQyUyMHRhZ3MlM0QlNUIlMjJHUlBPJTIyJTJDJTIwJTIyUmVhc29uaW5nLUNvdXJzZSUyMiU1RCUwQSk=",highlighted:`merged_model = trainer.model.merge_and_unload()
merged_model.push_to_hub(
    <span class="hljs-string">&quot;SmolGRPO-135M&quot;</span>, private=<span class="hljs-literal">False</span>, tags=[<span class="hljs-string">&quot;GRPO&quot;</span>, <span class="hljs-string">&quot;Reasoning-Course&quot;</span>]
)`,wrap:!1}}),he=new w({props:{title:"Generate text",local:"generate-text",headingTag:"h2"}}),we=new c({props:{code:"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",highlighted:`prompt = <span class="hljs-string">&quot;&quot;&quot;
# A long document about the Cat

The cat (Felis catus), also referred to as the domestic cat or house cat, is a small 
domesticated carnivorous mammal. It is the only domesticated species of the family Felidae.
Advances in archaeology and genetics have shown that the domestication of the cat occurred
in the Near East around 7500 BC. It is commonly kept as a pet and farm cat, but also ranges
freely as a feral cat avoiding human contact. It is valued by humans for companionship and
its ability to kill vermin. Its retractable claws are adapted to killing small prey species
such as mice and rats. It has a strong, flexible body, quick reflexes, and sharp teeth,
and its night vision and sense of smell are well developed. It is a social species,
but a solitary hunter and a crepuscular predator. Cat communication includes
vocalizationsâ€”including meowing, purring, trilling, hissing, growling, and gruntingâ€”as
well as body language. It can hear sounds too faint or too high in frequency for human ears,
such as those made by small mammals. It secretes and perceives pheromones.
&quot;&quot;&quot;</span>

messages = [
    {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: prompt},
]`,wrap:!1}}),fe=new c({props:{code:"JTIzJTIwR2VuZXJhdGUlMjB0ZXh0JTBBZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBZ2VuZXJhdG9yJTIwJTNEJTIwcGlwZWxpbmUoJTIydGV4dC1nZW5lcmF0aW9uJTIyJTJDJTIwbW9kZWwlM0QlMjJTbW9sR1JQTy0xMzVNJTIyKSUwQSUwQSUyMyUyMyUyME9yJTIwdXNlJTIwdGhlJTIwbW9kZWwlMjBhbmQlMjB0b2tlbml6ZXIlMjB3ZSUyMGRlZmluZWQlMjBlYXJsaWVyJTBBJTIzJTIwZ2VuZXJhdG9yJTIwJTNEJTIwcGlwZWxpbmUoJTIydGV4dC1nZW5lcmF0aW9uJTIyJTJDJTIwbW9kZWwlM0Rtb2RlbCUyQyUyMHRva2VuaXplciUzRHRva2VuaXplciklMEElMEFnZW5lcmF0ZV9rd2FyZ3MlMjAlM0QlMjAlN0IlMEElMjAlMjAlMjAlMjAlMjJtYXhfbmV3X3Rva2VucyUyMiUzQSUyMDI1NiUyQyUwQSUyMCUyMCUyMCUyMCUyMmRvX3NhbXBsZSUyMiUzQSUyMFRydWUlMkMlMEElMjAlMjAlMjAlMjAlMjJ0ZW1wZXJhdHVyZSUyMiUzQSUyMDAuNSUyQyUwQSUyMCUyMCUyMCUyMCUyMm1pbl9wJTIyJTNBJTIwMC4xJTJDJTBBJTdEJTBBJTBBZ2VuZXJhdGVkX3RleHQlMjAlM0QlMjBnZW5lcmF0b3IobWVzc2FnZXMlMkMlMjBnZW5lcmF0ZV9rd2FyZ3MlM0RnZW5lcmF0ZV9rd2FyZ3MpJTBBJTBBcHJpbnQoZ2VuZXJhdGVkX3RleHQp",highlighted:`<span class="hljs-comment"># Generate text</span>
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

generator = pipeline(<span class="hljs-string">&quot;text-generation&quot;</span>, model=<span class="hljs-string">&quot;SmolGRPO-135M&quot;</span>)

<span class="hljs-comment">## Or use the model and tokenizer we defined earlier</span>
<span class="hljs-comment"># generator = pipeline(&quot;text-generation&quot;, model=model, tokenizer=tokenizer)</span>

generate_kwargs = {
    <span class="hljs-string">&quot;max_new_tokens&quot;</span>: <span class="hljs-number">256</span>,
    <span class="hljs-string">&quot;do_sample&quot;</span>: <span class="hljs-literal">True</span>,
    <span class="hljs-string">&quot;temperature&quot;</span>: <span class="hljs-number">0.5</span>,
    <span class="hljs-string">&quot;min_p&quot;</span>: <span class="hljs-number">0.1</span>,
}

generated_text = generator(messages, generate_kwargs=generate_kwargs)

<span class="hljs-built_in">print</span>(generated_text)`,wrap:!1}}),Te=new w({props:{title:"Conclusion",local:"conclusion",headingTag:"h1"}}),{c(){u=i("meta"),J=s(),T=i("p"),je=s(),r(g.$$.fragment),$e=s(),r(b.$$.fragment),Ie=s(),U=i("p"),U.textContent=Ct,Ge=s(),r(f.$$.fragment),Ce=s(),r(j.$$.fragment),Be=s(),$=i("p"),$.textContent=Bt,Ze=s(),r(I.$$.fragment),ve=s(),G=i("p"),G.textContent=Zt,We=s(),r(C.$$.fragment),xe=s(),r(B.$$.fragment),Re=s(),Z=i("p"),Z.textContent=vt,Xe=s(),r(v.$$.fragment),Fe=s(),W=i("p"),W.textContent=Wt,_e=s(),r(x.$$.fragment),ke=s(),R=i("p"),R.innerHTML=xt,Qe=s(),r(X.$$.fragment),Ve=s(),r(F.$$.fragment),Ye=s(),_=i("p"),_.textContent=Rt,ze=s(),k=i("p"),k.innerHTML=Xt,Ne=s(),Q=i("p"),Q.innerHTML=Ft,Ee=s(),r(V.$$.fragment),He=s(),r(Y.$$.fragment),Ae=s(),z=i("p"),z.textContent=_t,Se=s(),N=i("p"),N.innerHTML=kt,qe=s(),r(E.$$.fragment),Le=s(),r(H.$$.fragment),Pe=s(),r(A.$$.fragment),De=s(),S=i("p"),S.textContent=Qt,Oe=s(),r(q.$$.fragment),Ke=s(),r(L.$$.fragment),et=s(),P=i("p"),P.innerHTML=Vt,tt=s(),D=i("p"),D.innerHTML=Yt,lt=s(),r(O.$$.fragment),nt=s(),K=i("p"),K.textContent=zt,st=s(),r(ee.$$.fragment),at=s(),te=i("p"),te.textContent=Nt,it=s(),r(le.$$.fragment),ot=s(),ne=i("p"),ne.innerHTML=Et,rt=s(),r(se.$$.fragment),mt=s(),ae=i("p"),ae.innerHTML=Ht,pt=s(),ie=i("p"),ie.textContent=At,Mt=s(),oe=i("p"),oe.textContent=St,dt=s(),re=i("p"),re.innerHTML=qt,yt=s(),me=i("p"),me.textContent=Lt,ht=s(),pe=i("p"),pe.innerHTML=Pt,ut=s(),r(Me.$$.fragment),ct=s(),de=i("p"),de.textContent=Dt,wt=s(),r(ye.$$.fragment),Jt=s(),r(he.$$.fragment),ft=s(),ue=i("p"),ue.textContent=Ot,Tt=s(),ce=i("p"),ce.textContent=Kt,gt=s(),r(we.$$.fragment),bt=s(),Je=i("p"),Je.textContent=el,Ut=s(),r(fe.$$.fragment),jt=s(),r(Te.$$.fragment),$t=s(),ge=i("p"),ge.textContent=tl,It=s(),be=i("p"),this.h()},l(e){const t=ml("svelte-u9bgzb",document.head);u=o(t,"META",{name:!0,content:!0}),t.forEach(l),J=a(e),T=o(e,"P",{}),nl(T).forEach(l),je=a(e),m(g.$$.fragment,e),$e=a(e),m(b.$$.fragment,e),Ie=a(e),U=o(e,"P",{"data-svelte-h":!0}),p(U)!=="svelte-cm5jhs"&&(U.textContent=Ct),Ge=a(e),m(f.$$.fragment,e),Ce=a(e),m(j.$$.fragment,e),Be=a(e),$=o(e,"P",{"data-svelte-h":!0}),p($)!=="svelte-ptnxo3"&&($.textContent=Bt),Ze=a(e),m(I.$$.fragment,e),ve=a(e),G=o(e,"P",{"data-svelte-h":!0}),p(G)!=="svelte-12snwaz"&&(G.textContent=Zt),We=a(e),m(C.$$.fragment,e),xe=a(e),m(B.$$.fragment,e),Re=a(e),Z=o(e,"P",{"data-svelte-h":!0}),p(Z)!=="svelte-1n1a8k6"&&(Z.textContent=vt),Xe=a(e),m(v.$$.fragment,e),Fe=a(e),W=o(e,"P",{"data-svelte-h":!0}),p(W)!=="svelte-1ew5fxu"&&(W.textContent=Wt),_e=a(e),m(x.$$.fragment,e),ke=a(e),R=o(e,"P",{"data-svelte-h":!0}),p(R)!=="svelte-26gya7"&&(R.innerHTML=xt),Qe=a(e),m(X.$$.fragment,e),Ve=a(e),m(F.$$.fragment,e),Ye=a(e),_=o(e,"P",{"data-svelte-h":!0}),p(_)!=="svelte-121fjkj"&&(_.textContent=Rt),ze=a(e),k=o(e,"P",{"data-svelte-h":!0}),p(k)!=="svelte-zw0jem"&&(k.innerHTML=Xt),Ne=a(e),Q=o(e,"P",{"data-svelte-h":!0}),p(Q)!=="svelte-31m4si"&&(Q.innerHTML=Ft),Ee=a(e),m(V.$$.fragment,e),He=a(e),m(Y.$$.fragment,e),Ae=a(e),z=o(e,"P",{"data-svelte-h":!0}),p(z)!=="svelte-1d01rwe"&&(z.textContent=_t),Se=a(e),N=o(e,"P",{"data-svelte-h":!0}),p(N)!=="svelte-zej957"&&(N.innerHTML=kt),qe=a(e),m(E.$$.fragment,e),Le=a(e),m(H.$$.fragment,e),Pe=a(e),m(A.$$.fragment,e),De=a(e),S=o(e,"P",{"data-svelte-h":!0}),p(S)!=="svelte-19qfksx"&&(S.textContent=Qt),Oe=a(e),m(q.$$.fragment,e),Ke=a(e),m(L.$$.fragment,e),et=a(e),P=o(e,"P",{"data-svelte-h":!0}),p(P)!=="svelte-yvl12o"&&(P.innerHTML=Vt),tt=a(e),D=o(e,"P",{"data-svelte-h":!0}),p(D)!=="svelte-1a9j2u8"&&(D.innerHTML=Yt),lt=a(e),m(O.$$.fragment,e),nt=a(e),K=o(e,"P",{"data-svelte-h":!0}),p(K)!=="svelte-djcfcf"&&(K.textContent=zt),st=a(e),m(ee.$$.fragment,e),at=a(e),te=o(e,"P",{"data-svelte-h":!0}),p(te)!=="svelte-1de2igi"&&(te.textContent=Nt),it=a(e),m(le.$$.fragment,e),ot=a(e),ne=o(e,"P",{"data-svelte-h":!0}),p(ne)!=="svelte-1xii7zd"&&(ne.innerHTML=Et),rt=a(e),m(se.$$.fragment,e),mt=a(e),ae=o(e,"P",{"data-svelte-h":!0}),p(ae)!=="svelte-87il9y"&&(ae.innerHTML=Ht),pt=a(e),ie=o(e,"P",{"data-svelte-h":!0}),p(ie)!=="svelte-eocx64"&&(ie.textContent=At),Mt=a(e),oe=o(e,"P",{"data-svelte-h":!0}),p(oe)!=="svelte-1qdyttt"&&(oe.textContent=St),dt=a(e),re=o(e,"P",{"data-svelte-h":!0}),p(re)!=="svelte-nb9yq5"&&(re.innerHTML=qt),yt=a(e),me=o(e,"P",{"data-svelte-h":!0}),p(me)!=="svelte-10noxip"&&(me.textContent=Lt),ht=a(e),pe=o(e,"P",{"data-svelte-h":!0}),p(pe)!=="svelte-1bbe9id"&&(pe.innerHTML=Pt),ut=a(e),m(Me.$$.fragment,e),ct=a(e),de=o(e,"P",{"data-svelte-h":!0}),p(de)!=="svelte-wu0gyd"&&(de.textContent=Dt),wt=a(e),m(ye.$$.fragment,e),Jt=a(e),m(he.$$.fragment,e),ft=a(e),ue=o(e,"P",{"data-svelte-h":!0}),p(ue)!=="svelte-u9gu30"&&(ue.textContent=Ot),Tt=a(e),ce=o(e,"P",{"data-svelte-h":!0}),p(ce)!=="svelte-1bqln8"&&(ce.textContent=Kt),gt=a(e),m(we.$$.fragment,e),bt=a(e),Je=o(e,"P",{"data-svelte-h":!0}),p(Je)!=="svelte-4yybog"&&(Je.textContent=el),Ut=a(e),m(fe.$$.fragment,e),jt=a(e),m(Te.$$.fragment,e),$t=a(e),ge=o(e,"P",{"data-svelte-h":!0}),p(ge)!=="svelte-1y8m2ev"&&(ge.textContent=tl),It=a(e),be=o(e,"P",{}),nl(be).forEach(l),this.h()},h(){sl(u,"name","hf:doc:metadata"),sl(u,"content",wl)},m(e,t){pl(document.head,u),n(e,J,t),n(e,T,t),n(e,je,t),M(g,e,t),n(e,$e,t),M(b,e,t),n(e,Ie,t),n(e,U,t),n(e,Ge,t),M(f,e,t),n(e,Ce,t),M(j,e,t),n(e,Be,t),n(e,$,t),n(e,Ze,t),M(I,e,t),n(e,ve,t),n(e,G,t),n(e,We,t),M(C,e,t),n(e,xe,t),M(B,e,t),n(e,Re,t),n(e,Z,t),n(e,Xe,t),M(v,e,t),n(e,Fe,t),n(e,W,t),n(e,_e,t),M(x,e,t),n(e,ke,t),n(e,R,t),n(e,Qe,t),M(X,e,t),n(e,Ve,t),M(F,e,t),n(e,Ye,t),n(e,_,t),n(e,ze,t),n(e,k,t),n(e,Ne,t),n(e,Q,t),n(e,Ee,t),M(V,e,t),n(e,He,t),M(Y,e,t),n(e,Ae,t),n(e,z,t),n(e,Se,t),n(e,N,t),n(e,qe,t),M(E,e,t),n(e,Le,t),M(H,e,t),n(e,Pe,t),M(A,e,t),n(e,De,t),n(e,S,t),n(e,Oe,t),M(q,e,t),n(e,Ke,t),M(L,e,t),n(e,et,t),n(e,P,t),n(e,tt,t),n(e,D,t),n(e,lt,t),M(O,e,t),n(e,nt,t),n(e,K,t),n(e,st,t),M(ee,e,t),n(e,at,t),n(e,te,t),n(e,it,t),M(le,e,t),n(e,ot,t),n(e,ne,t),n(e,rt,t),M(se,e,t),n(e,mt,t),n(e,ae,t),n(e,pt,t),n(e,ie,t),n(e,Mt,t),n(e,oe,t),n(e,dt,t),n(e,re,t),n(e,yt,t),n(e,me,t),n(e,ht,t),n(e,pe,t),n(e,ut,t),M(Me,e,t),n(e,ct,t),n(e,de,t),n(e,wt,t),M(ye,e,t),n(e,Jt,t),M(he,e,t),n(e,ft,t),n(e,ue,t),n(e,Tt,t),n(e,ce,t),n(e,gt,t),M(we,e,t),n(e,bt,t),n(e,Je,t),n(e,Ut,t),M(fe,e,t),n(e,jt,t),M(Te,e,t),n(e,$t,t),n(e,ge,t),n(e,It,t),n(e,be,t),Gt=!0},p(e,[t]){const ll={};t&2&&(ll.$$scope={dirty:t,ctx:e}),f.$set(ll)},i(e){Gt||(d(g.$$.fragment,e),d(b.$$.fragment,e),d(f.$$.fragment,e),d(j.$$.fragment,e),d(I.$$.fragment,e),d(C.$$.fragment,e),d(B.$$.fragment,e),d(v.$$.fragment,e),d(x.$$.fragment,e),d(X.$$.fragment,e),d(F.$$.fragment,e),d(V.$$.fragment,e),d(Y.$$.fragment,e),d(E.$$.fragment,e),d(H.$$.fragment,e),d(A.$$.fragment,e),d(q.$$.fragment,e),d(L.$$.fragment,e),d(O.$$.fragment,e),d(ee.$$.fragment,e),d(le.$$.fragment,e),d(se.$$.fragment,e),d(Me.$$.fragment,e),d(ye.$$.fragment,e),d(he.$$.fragment,e),d(we.$$.fragment,e),d(fe.$$.fragment,e),d(Te.$$.fragment,e),Gt=!0)},o(e){y(g.$$.fragment,e),y(b.$$.fragment,e),y(f.$$.fragment,e),y(j.$$.fragment,e),y(I.$$.fragment,e),y(C.$$.fragment,e),y(B.$$.fragment,e),y(v.$$.fragment,e),y(x.$$.fragment,e),y(X.$$.fragment,e),y(F.$$.fragment,e),y(V.$$.fragment,e),y(Y.$$.fragment,e),y(E.$$.fragment,e),y(H.$$.fragment,e),y(A.$$.fragment,e),y(q.$$.fragment,e),y(L.$$.fragment,e),y(O.$$.fragment,e),y(ee.$$.fragment,e),y(le.$$.fragment,e),y(se.$$.fragment,e),y(Me.$$.fragment,e),y(ye.$$.fragment,e),y(he.$$.fragment,e),y(we.$$.fragment,e),y(fe.$$.fragment,e),y(Te.$$.fragment,e),Gt=!1},d(e){e&&(l(J),l(T),l(je),l($e),l(Ie),l(U),l(Ge),l(Ce),l(Be),l($),l(Ze),l(ve),l(G),l(We),l(xe),l(Re),l(Z),l(Xe),l(Fe),l(W),l(_e),l(ke),l(R),l(Qe),l(Ve),l(Ye),l(_),l(ze),l(k),l(Ne),l(Q),l(Ee),l(He),l(Ae),l(z),l(Se),l(N),l(qe),l(Le),l(Pe),l(De),l(S),l(Oe),l(Ke),l(et),l(P),l(tt),l(D),l(lt),l(nt),l(K),l(st),l(at),l(te),l(it),l(ot),l(ne),l(rt),l(mt),l(ae),l(pt),l(ie),l(Mt),l(oe),l(dt),l(re),l(yt),l(me),l(ht),l(pe),l(ut),l(ct),l(de),l(wt),l(Jt),l(ft),l(ue),l(Tt),l(ce),l(gt),l(bt),l(Je),l(Ut),l(jt),l($t),l(ge),l(It),l(be)),l(u),h(g,e),h(b,e),h(f,e),h(j,e),h(I,e),h(C,e),h(B,e),h(v,e),h(x,e),h(X,e),h(F,e),h(V,e),h(Y,e),h(E,e),h(H,e),h(A,e),h(q,e),h(L,e),h(O,e),h(ee,e),h(le,e),h(se,e),h(Me,e),h(ye,e),h(he,e),h(we,e),h(fe,e),h(Te,e)}}}const wl='{"title":"Practical Exercise: Fine-tune a model with GRPO","local":"practical-exercise-fine-tune-a-model-with-grpo","sections":[{"title":"Install dependencies","local":"install-dependencies","sections":[],"depth":2},{"title":"Import and log in to Weights & Biases","local":"import-and-log-in-to-weights--biases","sections":[],"depth":2},{"title":"Load the dataset","local":"load-the-dataset","sections":[],"depth":2},{"title":"Load model","local":"load-model","sections":[],"depth":2},{"title":"Load LoRA","local":"load-lora","sections":[],"depth":2},{"title":"Define the reward function","local":"define-the-reward-function","sections":[],"depth":2},{"title":"Define the training arguments","local":"define-the-training-arguments","sections":[],"depth":2},{"title":"Push the model to the Hub during training","local":"push-the-model-to-the-hub-during-training","sections":[],"depth":2},{"title":"Interpret training results","local":"interpret-training-results","sections":[],"depth":2},{"title":"Save and publish the model","local":"save-and-publish-the-model","sections":[],"depth":2},{"title":"Generate text","local":"generate-text","sections":[],"depth":2}],"depth":1}';function Jl(Ue){return il(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class $l extends ol{constructor(u){super(),rl(this,u,Jl,cl,al,{})}}export{$l as component};
