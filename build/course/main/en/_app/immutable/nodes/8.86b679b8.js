import{s as Q,n as G,o as I}from"../chunks/scheduler.37c15a92.js";import{S as K,i as O,g as r,s as o,r as H,A as V,h as i,f as n,c as s,j as F,u as k,x as v,k as J,y as W,a,v as A,d as B,t as q,w as j}from"../chunks/index.2bf4358c.js";import{Y as X}from"../chunks/Youtube.1e50a667.js";import{C as Z}from"../chunks/CourseFloatingBanner.15ba07e6.js";import{H as ee}from"../chunks/Heading.8ada512a.js";function te(z){let l,w,_,x,m,C,c,b,f,E,d,S="Encoder models use only the encoder of a Transformer model. At each stage, the attention layers can access all the words in the initial sentence. These models are often characterized as having “bi-directional” attention, and are often called <em>auto-encoding models</em>.",T,u,U="The pretraining of these models usually revolves around somehow corrupting a given sentence (for instance, by masking random words in it) and tasking the model with finding or reconstructing the initial sentence.",y,p,N="Encoder models are best suited for tasks requiring an understanding of the full sentence, such as sentence classification, named entity recognition (and more generally word classification), and extractive question answering.",P,h,Y="Representatives of this family of models include:",L,g,D='<li><a href="https://huggingface.co/docs/transformers/model_doc/albert" rel="nofollow">ALBERT</a></li> <li><a href="https://huggingface.co/docs/transformers/model_doc/bert" rel="nofollow">BERT</a></li> <li><a href="https://huggingface.co/docs/transformers/model_doc/distilbert" rel="nofollow">DistilBERT</a></li> <li><a href="https://huggingface.co/docs/transformers/model_doc/electra" rel="nofollow">ELECTRA</a></li> <li><a href="https://huggingface.co/docs/transformers/model_doc/roberta" rel="nofollow">RoBERTa</a></li>',R,$,M;return m=new ee({props:{title:"Encoder models",local:"encoder-models",headingTag:"h1"}}),c=new Z({props:{chapter:1,classNames:"absolute z-10 right-0 top-0"}}),f=new X({props:{id:"MUqNwgPjJvQ"}}),{c(){l=r("meta"),w=o(),_=r("p"),x=o(),H(m.$$.fragment),C=o(),H(c.$$.fragment),b=o(),H(f.$$.fragment),E=o(),d=r("p"),d.innerHTML=S,T=o(),u=r("p"),u.textContent=U,y=o(),p=r("p"),p.textContent=N,P=o(),h=r("p"),h.textContent=Y,L=o(),g=r("ul"),g.innerHTML=D,R=o(),$=r("p"),this.h()},l(e){const t=V("svelte-u9bgzb",document.head);l=i(t,"META",{name:!0,content:!0}),t.forEach(n),w=s(e),_=i(e,"P",{}),F(_).forEach(n),x=s(e),k(m.$$.fragment,e),C=s(e),k(c.$$.fragment,e),b=s(e),k(f.$$.fragment,e),E=s(e),d=i(e,"P",{"data-svelte-h":!0}),v(d)!=="svelte-rb0n0h"&&(d.innerHTML=S),T=s(e),u=i(e,"P",{"data-svelte-h":!0}),v(u)!=="svelte-h6rvk4"&&(u.textContent=U),y=s(e),p=i(e,"P",{"data-svelte-h":!0}),v(p)!=="svelte-1l771dj"&&(p.textContent=N),P=s(e),h=i(e,"P",{"data-svelte-h":!0}),v(h)!=="svelte-s27rrg"&&(h.textContent=Y),L=s(e),g=i(e,"UL",{"data-svelte-h":!0}),v(g)!=="svelte-17o0nd4"&&(g.innerHTML=D),R=s(e),$=i(e,"P",{}),F($).forEach(n),this.h()},h(){J(l,"name","hf:doc:metadata"),J(l,"content",ne)},m(e,t){W(document.head,l),a(e,w,t),a(e,_,t),a(e,x,t),A(m,e,t),a(e,C,t),A(c,e,t),a(e,b,t),A(f,e,t),a(e,E,t),a(e,d,t),a(e,T,t),a(e,u,t),a(e,y,t),a(e,p,t),a(e,P,t),a(e,h,t),a(e,L,t),a(e,g,t),a(e,R,t),a(e,$,t),M=!0},p:G,i(e){M||(B(m.$$.fragment,e),B(c.$$.fragment,e),B(f.$$.fragment,e),M=!0)},o(e){q(m.$$.fragment,e),q(c.$$.fragment,e),q(f.$$.fragment,e),M=!1},d(e){e&&(n(w),n(_),n(x),n(C),n(b),n(E),n(d),n(T),n(u),n(y),n(p),n(P),n(h),n(L),n(g),n(R),n($)),n(l),j(m,e),j(c,e),j(f,e)}}}const ne='{"title":"Encoder models","local":"encoder-models","sections":[],"depth":1}';function ae(z){return I(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class me extends K{constructor(l){super(),O(this,l,ae,te,Q,{})}}export{me as component};
