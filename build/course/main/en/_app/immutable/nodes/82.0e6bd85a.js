import{s as D,n as G,o as O}from"../chunks/scheduler.37c15a92.js";import{S as W,i as J,g as s,s as o,r as M,A as Q,h as r,f as n,c as i,j as B,u as N,x as v,k as j,y as V,a,v as U,d as A,t as F,w as K}from"../chunks/index.2bf4358c.js";import{Y as X}from"../chunks/Youtube.1e50a667.js";import{C as Z}from"../chunks/CourseFloatingBanner.15ba07e6.js";import{H as ee}from"../chunks/Heading.8ada512a.js";function te(q){let l,y,w,_,u,x,m,P,f,z="If youâ€™ve made it this far in the course, congratulations â€” you now have all the knowledge and tools you need to tackle (almost) any NLP task with ðŸ¤— Transformers and the Hugging Face ecosystem!",b,h,I="We have seen a lot of different data collators, so we made this little video to help you find which one to use for each task:",C,c,k,d,R="After completing this lightning tour through the core NLP tasks, you should:",L,p,S="<li>Know which architectures (encoder, decoder, or encoder-decoder) are best suited for each task</li> <li>Understand the difference between pretraining and fine-tuning a language model</li> <li>Know how to train Transformer models using either the <code>Trainer</code> API and distributed training features of ðŸ¤— Accelerate or TensorFlow and Keras, depending on which track youâ€™ve been following</li> <li>Understand the meaning and limitations of metrics like ROUGE and BLEU for text generation tasks</li> <li>Know how to interact with your fine-tuned models, both on the Hub and using the <code>pipeline</code> from ðŸ¤— Transformers</li>",T,g,Y="Despite all this knowledge, there will come a time when youâ€™ll either encounter a difficult bug in your code or have a question about how to solve a particular NLP problem. Fortunately, the Hugging Face community is here to help you! In the final chapter of this part of the course, weâ€™ll explore how you can debug your Transformer models and ask for help effectively.",H,$,E;return u=new ee({props:{title:"Mastering NLP",local:"mastering-nlp",headingTag:"h1"}}),m=new Z({props:{chapter:7,classNames:"absolute z-10 right-0 top-0"}}),c=new X({props:{id:"-RPeakdlHYo"}}),{c(){l=s("meta"),y=o(),w=s("p"),_=o(),M(u.$$.fragment),x=o(),M(m.$$.fragment),P=o(),f=s("p"),f.textContent=z,b=o(),h=s("p"),h.textContent=I,C=o(),M(c.$$.fragment),k=o(),d=s("p"),d.textContent=R,L=o(),p=s("ul"),p.innerHTML=S,T=o(),g=s("p"),g.textContent=Y,H=o(),$=s("p"),this.h()},l(e){const t=Q("svelte-u9bgzb",document.head);l=r(t,"META",{name:!0,content:!0}),t.forEach(n),y=i(e),w=r(e,"P",{}),B(w).forEach(n),_=i(e),N(u.$$.fragment,e),x=i(e),N(m.$$.fragment,e),P=i(e),f=r(e,"P",{"data-svelte-h":!0}),v(f)!=="svelte-1khv5eu"&&(f.textContent=z),b=i(e),h=r(e,"P",{"data-svelte-h":!0}),v(h)!=="svelte-13if1qi"&&(h.textContent=I),C=i(e),N(c.$$.fragment,e),k=i(e),d=r(e,"P",{"data-svelte-h":!0}),v(d)!=="svelte-6vdyiz"&&(d.textContent=R),L=i(e),p=r(e,"UL",{"data-svelte-h":!0}),v(p)!=="svelte-11e1hxw"&&(p.innerHTML=S),T=i(e),g=r(e,"P",{"data-svelte-h":!0}),v(g)!=="svelte-lulsew"&&(g.textContent=Y),H=i(e),$=r(e,"P",{}),B($).forEach(n),this.h()},h(){j(l,"name","hf:doc:metadata"),j(l,"content",ne)},m(e,t){V(document.head,l),a(e,y,t),a(e,w,t),a(e,_,t),U(u,e,t),a(e,x,t),U(m,e,t),a(e,P,t),a(e,f,t),a(e,b,t),a(e,h,t),a(e,C,t),U(c,e,t),a(e,k,t),a(e,d,t),a(e,L,t),a(e,p,t),a(e,T,t),a(e,g,t),a(e,H,t),a(e,$,t),E=!0},p:G,i(e){E||(A(u.$$.fragment,e),A(m.$$.fragment,e),A(c.$$.fragment,e),E=!0)},o(e){F(u.$$.fragment,e),F(m.$$.fragment,e),F(c.$$.fragment,e),E=!1},d(e){e&&(n(y),n(w),n(_),n(x),n(P),n(f),n(b),n(h),n(C),n(k),n(d),n(L),n(p),n(T),n(g),n(H),n($)),n(l),K(u,e),K(m,e),K(c,e)}}}const ne='{"title":"Mastering NLP","local":"mastering-nlp","sections":[],"depth":1}';function ae(q){return O(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ue extends W{constructor(l){super(),J(this,l,ae,te,D,{})}}export{ue as component};
