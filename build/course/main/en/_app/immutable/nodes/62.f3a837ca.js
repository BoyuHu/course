import{s as A,n as N,o as W}from"../chunks/scheduler.37c15a92.js";import{S as j,i as B,g as h,s as m,r as T,A as I,h as f,f as a,c,j as D,u as M,x as P,k as E,y as U,a as s,v as S,d as q,t as z,w as F}from"../chunks/index.2bf4358c.js";import{C as Q}from"../chunks/CourseFloatingBanner.15ba07e6.js";import{H as R}from"../chunks/Heading.8ada512a.js";function G(x){let n,g,p,_,o,w,i,y,r,C="Well, that was quite a tour through the ðŸ¤— Datasets library â€” congratulations on making it this far! With the knowledge that youâ€™ve gained from this chapter, you should be able to:",$,l,H="<li>Load datasets from anywhere, be it the Hugging Face Hub, your laptop, or a remote server at your company.</li> <li>Wrangle your data using a mix of the <code>Dataset.map()</code> and <code>Dataset.filter()</code> functions.</li> <li>Quickly switch between data formats like Pandas and NumPy using <code>Dataset.set_format()</code>.</li> <li>Create your very own dataset and push it to the Hugging Face Hub.</li> <li>Embed your documents using a Transformer model and build a semantic search engine using FAISS.</li>",b,u,L='In <a href="/course/chapter7">Chapter 7</a>, weâ€™ll put all of this to good use as we take a deep dive into the core NLP tasks that Transformer models are great for. Before jumping ahead, though, put your knowledge of ðŸ¤— Datasets to the test with a quick quiz!',v,d,k;return o=new R({props:{title:"ðŸ¤— Datasets, check!",local:"datasets-check",headingTag:"h1"}}),i=new Q({props:{chapter:5,classNames:"absolute z-10 right-0 top-0"}}),{c(){n=h("meta"),g=m(),p=h("p"),_=m(),T(o.$$.fragment),w=m(),T(i.$$.fragment),y=m(),r=h("p"),r.textContent=C,$=m(),l=h("ul"),l.innerHTML=H,b=m(),u=h("p"),u.innerHTML=L,v=m(),d=h("p"),this.h()},l(t){const e=I("svelte-u9bgzb",document.head);n=f(e,"META",{name:!0,content:!0}),e.forEach(a),g=c(t),p=f(t,"P",{}),D(p).forEach(a),_=c(t),M(o.$$.fragment,t),w=c(t),M(i.$$.fragment,t),y=c(t),r=f(t,"P",{"data-svelte-h":!0}),P(r)!=="svelte-b42zfc"&&(r.textContent=C),$=c(t),l=f(t,"UL",{"data-svelte-h":!0}),P(l)!=="svelte-vwrb79"&&(l.innerHTML=H),b=c(t),u=f(t,"P",{"data-svelte-h":!0}),P(u)!=="svelte-cfae0"&&(u.innerHTML=L),v=c(t),d=f(t,"P",{}),D(d).forEach(a),this.h()},h(){E(n,"name","hf:doc:metadata"),E(n,"content",J)},m(t,e){U(document.head,n),s(t,g,e),s(t,p,e),s(t,_,e),S(o,t,e),s(t,w,e),S(i,t,e),s(t,y,e),s(t,r,e),s(t,$,e),s(t,l,e),s(t,b,e),s(t,u,e),s(t,v,e),s(t,d,e),k=!0},p:N,i(t){k||(q(o.$$.fragment,t),q(i.$$.fragment,t),k=!0)},o(t){z(o.$$.fragment,t),z(i.$$.fragment,t),k=!1},d(t){t&&(a(g),a(p),a(_),a(w),a(y),a(r),a($),a(l),a(b),a(u),a(v),a(d)),a(n),F(o,t),F(i,t)}}}const J='{"title":"ðŸ¤— Datasets, check!","local":"datasets-check","sections":[],"depth":1}';function K(x){return W(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Z extends j{constructor(n){super(),B(this,n,K,G,A,{})}}export{Z as component};
