import{s as Ce,n as Ie,o as Ge}from"../chunks/scheduler.37c15a92.js";import{S as Ze,i as Ae,g as N,s as n,r,A as _e,h as P,f as s,c as a,j as je,u as o,x as ze,k as Be,y as Fe,a as i,v as l,d as m,t as p,w as h}from"../chunks/index.2bf4358c.js";import{C as We}from"../chunks/CodeBlock.4f5fc1ad.js";import{C as Se}from"../chunks/CourseFloatingBanner.15ba07e6.js";import{Q as c}from"../chunks/Question.668688bc.js";import{H as f}from"../chunks/Heading.8ada512a.js";function Ve(Je){let u,Q,R,K,d,D,g,L,$,ve="This chapter covered a lot of ground! Don‚Äôt worry if you didn‚Äôt grasp all the details; the next chapters will help you understand how things work under the hood.",X,w,Ue="First, though, let‚Äôs test what you learned in this chapter!",O,y,ee,b,te,x,se,T,ie,k,ne,q,ae,M,re,W,oe,J,le,v,me,U,pe,j,he,z,fe,B,ce,C,ue,I,de,G,ge,Z,$e,A,we,_,ye,F,be,S,xe,V,Te,H,ke,E,qe,Y,Me;return d=new f({props:{title:"End-of-chapter quiz",local:"end-of-chapter-quiz",headingTag:"h1"}}),g=new Se({props:{chapter:1,classNames:"absolute z-10 right-0 top-0"}}),y=new f({props:{title:"1. Explore the Hub and look for the roberta-large-mnli checkpoint. What task does it perform?",local:"1-explore-the-hub-and-look-for-the-roberta-large-mnli-checkpoint-what-task-does-it-perform",headingTag:"h3"}}),b=new c({props:{choices:[{text:"Summarization",explain:'Look again on the <a href="https://huggingface.co/roberta-large-mnli">roberta-large-mnli page</a>.'},{text:"Text classification",explain:"More precisely, it classifies if two sentences are logically linked across three labels (contradiction, neutral, entailment) ‚Äî a task also called <em>natural language inference</em>.",correct:!0},{text:"Text generation",explain:'Look again on the <a href="https://huggingface.co/roberta-large-mnli">roberta-large-mnli page</a>.'}]}}),x=new f({props:{title:"2. What will the following code return?",local:"2-what-will-the-following-code-return",headingTag:"h3"}}),T=new We({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBbmVyJTIwJTNEJTIwcGlwZWxpbmUoJTIybmVyJTIyJTJDJTIwZ3JvdXBlZF9lbnRpdGllcyUzRFRydWUpJTBBbmVyKCUyMk15JTIwbmFtZSUyMGlzJTIwU3lsdmFpbiUyMGFuZCUyMEklMjB3b3JrJTIwYXQlMjBIdWdnaW5nJTIwRmFjZSUyMGluJTIwQnJvb2tseW4uJTIyKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

ner = pipeline(<span class="hljs-string">&quot;ner&quot;</span>, grouped_entities=<span class="hljs-literal">True</span>)
ner(<span class="hljs-string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn.&quot;</span>)`,wrap:!1}}),k=new c({props:{choices:[{text:'It will return classification scores for this sentence, with labels "positive" or "negative".',explain:"This is incorrect ‚Äî this would be a <code>sentiment-analysis</code> pipeline."},{text:"It will return a generated text completing this sentence.",explain:"This is incorrect ‚Äî it would be a <code>text-generation</code> pipeline."},{text:"It will return the words representing persons, organizations or locations.",explain:'Furthermore, with <code>grouped_entities=True</code>, it will group together the words belonging to the same entity, like "Hugging Face".',correct:!0}]}}),q=new f({props:{title:"3. What should replace ‚Ä¶ in this code sample?",local:"3-what-should-replace--in-this-code-sample",headingTag:"h3"}}),M=new We({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBZmlsbGVyJTIwJTNEJTIwcGlwZWxpbmUoJTIyZmlsbC1tYXNrJTIyJTJDJTIwbW9kZWwlM0QlMjJiZXJ0LWJhc2UtY2FzZWQlMjIpJTBBcmVzdWx0JTIwJTNEJTIwZmlsbGVyKCUyMi4uLiUyMik=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

filler = pipeline(<span class="hljs-string">&quot;fill-mask&quot;</span>, model=<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
result = filler(<span class="hljs-string">&quot;...&quot;</span>)`,wrap:!1}}),W=new c({props:{choices:[{text:"This &#60;mask> has been waiting for you.",explain:"This is incorrect. Check out the <code>bert-base-cased</code> model card and try to spot your mistake."},{text:"This [MASK] has been waiting for you.",explain:"Correct! This model's mask token is [MASK].",correct:!0},{text:"This man has been waiting for you.",explain:"This is incorrect. This pipeline fills in masked words, so it needs a mask token somewhere."}]}}),J=new f({props:{title:"4. Why will this code fail?",local:"4-why-will-this-code-fail",headingTag:"h3"}}),v=new We({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBY2xhc3NpZmllciUyMCUzRCUyMHBpcGVsaW5lKCUyMnplcm8tc2hvdC1jbGFzc2lmaWNhdGlvbiUyMiklMEFyZXN1bHQlMjAlM0QlMjBjbGFzc2lmaWVyKCUyMlRoaXMlMjBpcyUyMGElMjBjb3Vyc2UlMjBhYm91dCUyMHRoZSUyMFRyYW5zZm9ybWVycyUyMGxpYnJhcnklMjIp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

classifier = pipeline(<span class="hljs-string">&quot;zero-shot-classification&quot;</span>)
result = classifier(<span class="hljs-string">&quot;This is a course about the Transformers library&quot;</span>)`,wrap:!1}}),U=new c({props:{choices:[{text:"This pipeline requires that labels be given to classify this text.",explain:"Right ‚Äî the correct code needs to include <code>candidate_labels=[...]</code>.",correct:!0},{text:"This pipeline requires several sentences, not just one.",explain:"This is incorrect, though when properly used, this pipeline can take a list of sentences to process (like all other pipelines)."},{text:"The ü§ó Transformers library is broken, as usual.",explain:"We won't dignify this answer with a comment!"},{text:"This pipeline requires longer inputs; this one is too short.",explain:"This is incorrect. Note that a very long text will be truncated when processed by this pipeline."}]}}),j=new f({props:{title:"5. What does ‚Äútransfer learning‚Äù mean?",local:"5-what-does-transfer-learning-mean",headingTag:"h3"}}),z=new c({props:{choices:[{text:"Transferring the knowledge of a pretrained model to a new model by training it on the same dataset.",explain:"No, that would be two versions of the same model."},{text:"Transferring the knowledge of a pretrained model to a new model by initializing the second model with the first model's weights.",explain:"Correct: when the second model is trained on a new task, it *transfers* the knowledge of the first model.",correct:!0},{text:"Transferring the knowledge of a pretrained model to a new model by building the second model with the same architecture as the first model.",explain:"The architecture is just the way the model is built; there is no knowledge shared or transferred in this case."}]}}),B=new f({props:{title:"6. True or false? A language model usually does not need labels for its pretraining.",local:"6-true-or-false-a-language-model-usually-does-not-need-labels-for-its-pretraining",headingTag:"h3"}}),C=new c({props:{choices:[{text:"True",explain:"The pretraining is usually <em>self-supervised</em>, which means the labels are created automatically from the inputs (like predicting the next word or filling in some masked words).",correct:!0},{text:"False",explain:"This is not the correct answer."}]}}),I=new f({props:{title:"7. Select the sentence that best describes the terms ‚Äúmodel‚Äù, ‚Äúarchitecture‚Äù, and ‚Äúweights‚Äù.",local:"7-select-the-sentence-that-best-describes-the-terms-model-architecture-and-weights",headingTag:"h3"}}),G=new c({props:{choices:[{text:"If a model is a building, its architecture is the blueprint and the weights are the people living inside.",explain:"Following this metaphor, the weights would be the bricks and other materials used to construct the building."},{text:"An architecture is a map to build a model and its weights are the cities represented on the map.",explain:"The problem with this metaphor is that a map usually represents one existing reality (there is only one city in France named Paris). For a given architecture, multiple weights are possible."},{text:"An architecture is a succession of mathematical functions to build a model and its weights are those functions parameters.",explain:"The same set of mathematical functions (architecture) can be used to build different models by using different parameters (weights).",correct:!0}]}}),Z=new f({props:{title:"8. Which of these types of models would you use for completing prompts with generated text?",local:"8-which-of-these-types-of-models-would-you-use-for-completing-prompts-with-generated-text",headingTag:"h3"}}),A=new c({props:{choices:[{text:"An encoder model",explain:"An encoder model generates a representation of the whole sentence that is better suited for tasks like classification."},{text:"A decoder model",explain:"Decoder models are perfectly suited for text generation from a prompt.",correct:!0},{text:"A sequence-to-sequence model",explain:"Sequence-to-sequence models are better suited for tasks where you want to generate sentences in relation to the input sentences, not a given prompt."}]}}),_=new f({props:{title:"9. Which of those types of models would you use for summarizing texts?",local:"9-which-of-those-types-of-models-would-you-use-for-summarizing-texts",headingTag:"h3"}}),F=new c({props:{choices:[{text:"An encoder model",explain:"An encoder model generates a representation of the whole sentence that is better suited for tasks like classification."},{text:"A decoder model",explain:"Decoder models are good for generating output text (like summaries), but they don't have the ability to exploit a context like the whole text to summarize."},{text:"A sequence-to-sequence model",explain:"Sequence-to-sequence models are perfectly suited for a summarization task.",correct:!0}]}}),S=new f({props:{title:"10. Which of these types of models would you use for classifying text inputs according to certain labels?",local:"10-which-of-these-types-of-models-would-you-use-for-classifying-text-inputs-according-to-certain-labels",headingTag:"h3"}}),V=new c({props:{choices:[{text:"An encoder model",explain:"An encoder model generates a representation of the whole sentence which is perfectly suited for a task like classification.",correct:!0},{text:"A decoder model",explain:"Decoder models are good for generating output texts, not extracting a label out of a sentence."},{text:"A sequence-to-sequence model",explain:"Sequence-to-sequence models are better suited for tasks where you want to generate text based on an input sentence, not a label."}]}}),H=new f({props:{title:"11. What possible source can the bias observed in a model have?",local:"11-what-possible-source-can-the-bias-observed-in-a-model-have",headingTag:"h3"}}),E=new c({props:{choices:[{text:"The model is a fine-tuned version of a pretrained model and it picked up its bias from it.",explain:"When applying Transfer Learning, the bias in the pretrained model used persists in the fine-tuned model.",correct:!0},{text:"The data the model was trained on is biased.",explain:"This is the most obvious source of bias, but not the only one.",correct:!0},{text:"The metric the model was optimizing for is biased.",explain:"A less obvious source of bias is the way the model is trained. Your model will blindly optimize for whatever metric you chose, without any second thoughts.",correct:!0}]}}),{c(){u=N("meta"),Q=n(),R=N("p"),K=n(),r(d.$$.fragment),D=n(),r(g.$$.fragment),L=n(),$=N("p"),$.textContent=ve,X=n(),w=N("p"),w.textContent=Ue,O=n(),r(y.$$.fragment),ee=n(),r(b.$$.fragment),te=n(),r(x.$$.fragment),se=n(),r(T.$$.fragment),ie=n(),r(k.$$.fragment),ne=n(),r(q.$$.fragment),ae=n(),r(M.$$.fragment),re=n(),r(W.$$.fragment),oe=n(),r(J.$$.fragment),le=n(),r(v.$$.fragment),me=n(),r(U.$$.fragment),pe=n(),r(j.$$.fragment),he=n(),r(z.$$.fragment),fe=n(),r(B.$$.fragment),ce=n(),r(C.$$.fragment),ue=n(),r(I.$$.fragment),de=n(),r(G.$$.fragment),ge=n(),r(Z.$$.fragment),$e=n(),r(A.$$.fragment),we=n(),r(_.$$.fragment),ye=n(),r(F.$$.fragment),be=n(),r(S.$$.fragment),xe=n(),r(V.$$.fragment),Te=n(),r(H.$$.fragment),ke=n(),r(E.$$.fragment),qe=n(),Y=N("p"),this.h()},l(e){const t=_e("svelte-u9bgzb",document.head);u=P(t,"META",{name:!0,content:!0}),t.forEach(s),Q=a(e),R=P(e,"P",{}),je(R).forEach(s),K=a(e),o(d.$$.fragment,e),D=a(e),o(g.$$.fragment,e),L=a(e),$=P(e,"P",{"data-svelte-h":!0}),ze($)!=="svelte-bcp370"&&($.textContent=ve),X=a(e),w=P(e,"P",{"data-svelte-h":!0}),ze(w)!=="svelte-zajngf"&&(w.textContent=Ue),O=a(e),o(y.$$.fragment,e),ee=a(e),o(b.$$.fragment,e),te=a(e),o(x.$$.fragment,e),se=a(e),o(T.$$.fragment,e),ie=a(e),o(k.$$.fragment,e),ne=a(e),o(q.$$.fragment,e),ae=a(e),o(M.$$.fragment,e),re=a(e),o(W.$$.fragment,e),oe=a(e),o(J.$$.fragment,e),le=a(e),o(v.$$.fragment,e),me=a(e),o(U.$$.fragment,e),pe=a(e),o(j.$$.fragment,e),he=a(e),o(z.$$.fragment,e),fe=a(e),o(B.$$.fragment,e),ce=a(e),o(C.$$.fragment,e),ue=a(e),o(I.$$.fragment,e),de=a(e),o(G.$$.fragment,e),ge=a(e),o(Z.$$.fragment,e),$e=a(e),o(A.$$.fragment,e),we=a(e),o(_.$$.fragment,e),ye=a(e),o(F.$$.fragment,e),be=a(e),o(S.$$.fragment,e),xe=a(e),o(V.$$.fragment,e),Te=a(e),o(H.$$.fragment,e),ke=a(e),o(E.$$.fragment,e),qe=a(e),Y=P(e,"P",{}),je(Y).forEach(s),this.h()},h(){Be(u,"name","hf:doc:metadata"),Be(u,"content",He)},m(e,t){Fe(document.head,u),i(e,Q,t),i(e,R,t),i(e,K,t),l(d,e,t),i(e,D,t),l(g,e,t),i(e,L,t),i(e,$,t),i(e,X,t),i(e,w,t),i(e,O,t),l(y,e,t),i(e,ee,t),l(b,e,t),i(e,te,t),l(x,e,t),i(e,se,t),l(T,e,t),i(e,ie,t),l(k,e,t),i(e,ne,t),l(q,e,t),i(e,ae,t),l(M,e,t),i(e,re,t),l(W,e,t),i(e,oe,t),l(J,e,t),i(e,le,t),l(v,e,t),i(e,me,t),l(U,e,t),i(e,pe,t),l(j,e,t),i(e,he,t),l(z,e,t),i(e,fe,t),l(B,e,t),i(e,ce,t),l(C,e,t),i(e,ue,t),l(I,e,t),i(e,de,t),l(G,e,t),i(e,ge,t),l(Z,e,t),i(e,$e,t),l(A,e,t),i(e,we,t),l(_,e,t),i(e,ye,t),l(F,e,t),i(e,be,t),l(S,e,t),i(e,xe,t),l(V,e,t),i(e,Te,t),l(H,e,t),i(e,ke,t),l(E,e,t),i(e,qe,t),i(e,Y,t),Me=!0},p:Ie,i(e){Me||(m(d.$$.fragment,e),m(g.$$.fragment,e),m(y.$$.fragment,e),m(b.$$.fragment,e),m(x.$$.fragment,e),m(T.$$.fragment,e),m(k.$$.fragment,e),m(q.$$.fragment,e),m(M.$$.fragment,e),m(W.$$.fragment,e),m(J.$$.fragment,e),m(v.$$.fragment,e),m(U.$$.fragment,e),m(j.$$.fragment,e),m(z.$$.fragment,e),m(B.$$.fragment,e),m(C.$$.fragment,e),m(I.$$.fragment,e),m(G.$$.fragment,e),m(Z.$$.fragment,e),m(A.$$.fragment,e),m(_.$$.fragment,e),m(F.$$.fragment,e),m(S.$$.fragment,e),m(V.$$.fragment,e),m(H.$$.fragment,e),m(E.$$.fragment,e),Me=!0)},o(e){p(d.$$.fragment,e),p(g.$$.fragment,e),p(y.$$.fragment,e),p(b.$$.fragment,e),p(x.$$.fragment,e),p(T.$$.fragment,e),p(k.$$.fragment,e),p(q.$$.fragment,e),p(M.$$.fragment,e),p(W.$$.fragment,e),p(J.$$.fragment,e),p(v.$$.fragment,e),p(U.$$.fragment,e),p(j.$$.fragment,e),p(z.$$.fragment,e),p(B.$$.fragment,e),p(C.$$.fragment,e),p(I.$$.fragment,e),p(G.$$.fragment,e),p(Z.$$.fragment,e),p(A.$$.fragment,e),p(_.$$.fragment,e),p(F.$$.fragment,e),p(S.$$.fragment,e),p(V.$$.fragment,e),p(H.$$.fragment,e),p(E.$$.fragment,e),Me=!1},d(e){e&&(s(Q),s(R),s(K),s(D),s(L),s($),s(X),s(w),s(O),s(ee),s(te),s(se),s(ie),s(ne),s(ae),s(re),s(oe),s(le),s(me),s(pe),s(he),s(fe),s(ce),s(ue),s(de),s(ge),s($e),s(we),s(ye),s(be),s(xe),s(Te),s(ke),s(qe),s(Y)),s(u),h(d,e),h(g,e),h(y,e),h(b,e),h(x,e),h(T,e),h(k,e),h(q,e),h(M,e),h(W,e),h(J,e),h(v,e),h(U,e),h(j,e),h(z,e),h(B,e),h(C,e),h(I,e),h(G,e),h(Z,e),h(A,e),h(_,e),h(F,e),h(S,e),h(V,e),h(H,e),h(E,e)}}}const He='{"title":"End-of-chapter quiz","local":"end-of-chapter-quiz","sections":[{"title":"1. Explore the Hub and look for the roberta-large-mnli checkpoint. What task does it perform?","local":"1-explore-the-hub-and-look-for-the-roberta-large-mnli-checkpoint-what-task-does-it-perform","sections":[],"depth":3},{"title":"2. What will the following code return?","local":"2-what-will-the-following-code-return","sections":[],"depth":3},{"title":"3. What should replace ‚Ä¶ in this code sample?","local":"3-what-should-replace--in-this-code-sample","sections":[],"depth":3},{"title":"4. Why will this code fail?","local":"4-why-will-this-code-fail","sections":[],"depth":3},{"title":"5. What does ‚Äútransfer learning‚Äù mean?","local":"5-what-does-transfer-learning-mean","sections":[],"depth":3},{"title":"6. True or false? A language model usually does not need labels for its pretraining.","local":"6-true-or-false-a-language-model-usually-does-not-need-labels-for-its-pretraining","sections":[],"depth":3},{"title":"7. Select the sentence that best describes the terms ‚Äúmodel‚Äù, ‚Äúarchitecture‚Äù, and ‚Äúweights‚Äù.","local":"7-select-the-sentence-that-best-describes-the-terms-model-architecture-and-weights","sections":[],"depth":3},{"title":"8. Which of these types of models would you use for completing prompts with generated text?","local":"8-which-of-these-types-of-models-would-you-use-for-completing-prompts-with-generated-text","sections":[],"depth":3},{"title":"9. Which of those types of models would you use for summarizing texts?","local":"9-which-of-those-types-of-models-would-you-use-for-summarizing-texts","sections":[],"depth":3},{"title":"10. Which of these types of models would you use for classifying text inputs according to certain labels?","local":"10-which-of-these-types-of-models-would-you-use-for-classifying-text-inputs-according-to-certain-labels","sections":[],"depth":3},{"title":"11. What possible source can the bias observed in a model have?","local":"11-what-possible-source-can-the-bias-observed-in-a-model-have","sections":[],"depth":3}],"depth":1}';function Ee(Je){return Ge(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class De extends Ze{constructor(u){super(),Ae(this,u,Ee,Ve,Ce,{})}}export{De as component};
